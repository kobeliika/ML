{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc4d8959",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9f271ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2020-12-31-DynamicallyGeneratedHateDataset-entries-v0.1.csv', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "612bf66b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>type</th>\n",
       "      <th>model_wrong</th>\n",
       "      <th>db.model_preds</th>\n",
       "      <th>status</th>\n",
       "      <th>round</th>\n",
       "      <th>split</th>\n",
       "      <th>annotator</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10000</td>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97457</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10001</td>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>False</td>\n",
       "      <td>0.08233</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10002</td>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.92319</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10003</td>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.99006</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>gnzuctwed3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>10004</td>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.98836</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>40736</td>\n",
       "      <td>9995</td>\n",
       "      <td>we should forcibly remove all the foreigners f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.86945</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>40737</td>\n",
       "      <td>9996</td>\n",
       "      <td>we should forcibly remove all the immigrants f...</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.50039</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>40738</td>\n",
       "      <td>9997</td>\n",
       "      <td>dalits are unworthy of the Gods love</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.97652</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>40739</td>\n",
       "      <td>9998</td>\n",
       "      <td>dalits are worthless</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94326</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>40740</td>\n",
       "      <td>9999</td>\n",
       "      <td>dalits are deserves to be treated as lowlife</td>\n",
       "      <td>hate</td>\n",
       "      <td>notgiven</td>\n",
       "      <td>True</td>\n",
       "      <td>0.94324</td>\n",
       "      <td>dynabench entry</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>cagnluiznm</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40623 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0     id                                               text  \\\n",
       "0               1  10000  It should be legal for a husband to rape his wife   \n",
       "1               2  10001                            dalits are lowlife scum   \n",
       "2               3  10002                                dalits are lowlives   \n",
       "3               4  10003  It was a better world when women dare not ques...   \n",
       "4               5  10004  I don't work this hard so that those immigrant...   \n",
       "...           ...    ...                                                ...   \n",
       "40618       40736   9995  we should forcibly remove all the foreigners f...   \n",
       "40619       40737   9996  we should forcibly remove all the immigrants f...   \n",
       "40620       40738   9997               dalits are unworthy of the Gods love   \n",
       "40621       40739   9998                               dalits are worthless   \n",
       "40622       40740   9999       dalits are deserves to be treated as lowlife   \n",
       "\n",
       "      label      type model_wrong  db.model_preds           status round  \\\n",
       "0      hate  notgiven        True         0.97457  dynabench entry     1   \n",
       "1      hate  notgiven       False         0.08233  dynabench entry     1   \n",
       "2      hate  notgiven        True         0.92319  dynabench entry     1   \n",
       "3      hate  notgiven        True         0.99006  dynabench entry     1   \n",
       "4      hate  notgiven        True         0.98836  dynabench entry     1   \n",
       "...     ...       ...         ...             ...              ...   ...   \n",
       "40618  hate  notgiven        True         0.86945  dynabench entry     1   \n",
       "40619  hate  notgiven        True         0.50039  dynabench entry     1   \n",
       "40620  hate  notgiven        True         0.97652  dynabench entry     1   \n",
       "40621  hate  notgiven        True         0.94326  dynabench entry     1   \n",
       "40622  hate  notgiven        True         0.94324  dynabench entry     1   \n",
       "\n",
       "       split   annotator  \n",
       "0      train  gnzuctwed3  \n",
       "1       test  cagnluiznm  \n",
       "2      train  cagnluiznm  \n",
       "3       test  gnzuctwed3  \n",
       "4      train  cagnluiznm  \n",
       "...      ...         ...  \n",
       "40618  train  cagnluiznm  \n",
       "40619  train  cagnluiznm  \n",
       "40620  train  cagnluiznm  \n",
       "40621  train  cagnluiznm  \n",
       "40622  train  cagnluiznm  \n",
       "\n",
       "[40623 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb502c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['text','label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f0f36e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It should be legal for a husband to rape his wife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dalits are lowlife scum</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dalits are lowlives</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It was a better world when women dare not ques...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I don't work this hard so that those immigrant...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40618</th>\n",
       "      <td>we should forcibly remove all the foreigners f...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40619</th>\n",
       "      <td>we should forcibly remove all the immigrants f...</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40620</th>\n",
       "      <td>dalits are unworthy of the Gods love</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40621</th>\n",
       "      <td>dalits are worthless</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40622</th>\n",
       "      <td>dalits are deserves to be treated as lowlife</td>\n",
       "      <td>hate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40623 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "0      It should be legal for a husband to rape his wife  hate\n",
       "1                                dalits are lowlife scum  hate\n",
       "2                                    dalits are lowlives  hate\n",
       "3      It was a better world when women dare not ques...  hate\n",
       "4      I don't work this hard so that those immigrant...  hate\n",
       "...                                                  ...   ...\n",
       "40618  we should forcibly remove all the foreigners f...  hate\n",
       "40619  we should forcibly remove all the immigrants f...  hate\n",
       "40620               dalits are unworthy of the Gods love  hate\n",
       "40621                               dalits are worthless  hate\n",
       "40622       dalits are deserves to be treated as lowlife  hate\n",
       "\n",
       "[40623 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1efbf98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d46075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff23abf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextNormalizer(BaseEstimator, TransformerMixin):\n",
    "    def fit (self, X, y=None, **fit_params):\n",
    "        return self\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        X_copy = X.copy()\n",
    "        for i in range(len(X)):\n",
    "            X_copy[i] = ' '.join([token.lower()\n",
    "                                 for token in word_tokenize(X_copy[i])])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60bf2c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm= TextNormalizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad3c96c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ana apple a day keeps the doctor away !']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "norm.fit_transform(['Ana apple a day keeps the doctor away!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55f6470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stop_words):\n",
    "        self.stop_words = stop_words\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        self.general_freq = FreqDist()\n",
    "        for document in X:\n",
    "            tokens = word_tokenize(document)\n",
    "            freq = FreqDist(tokens)\n",
    "            self.general_freq.update(freq)\n",
    "        self.hapaxes = self.general_freq.hapaxes()\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        X_copy = X.copy()\n",
    "        for i in range(len(X)):\n",
    "            X_copy[i] = ' '.join([token for token in word_tokenize(X[i])\n",
    "                                 if token not in self.hapaxes and\n",
    "                                 token not in self.stop_words])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0d204a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words=stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d226f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_extractor = WordExtractor(stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "13930c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\n",
    "    'John is a preaty boy',\n",
    "    'Ann likes John',\n",
    "    'Ann likes cherry',\n",
    "    'Cherry is red'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "56737375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John', 'Ann likes John', 'Ann likes', '']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_extractor.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed337128",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ApplyStemmer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stemmer):\n",
    "        self.stemmer = stemmer\n",
    "    \n",
    "    def fit(self, X, y=None, **fit_tranform):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None, **fit_tranform):\n",
    "        X_copy = X.copy()\n",
    "        for i in range(len(X)):\n",
    "            X_copy[i] = ' '.join([self.stemmer.stem(token) \n",
    "                                  for token in word_tokenize(X_copy[i])])\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac2cce53",
   "metadata": {},
   "outputs": [],
   "source": [
    "porter_stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "30dce91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_stemmer = ApplyStemmer(porter_stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6f0cd7ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ana appl a day keep the doctor away !']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "apply_stemmer.fit_transform(['Ana apple a day keeps the doctor away!'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dad1af1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "027eb1b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ed42d589",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    (\"norm\", TextNormalizer()),\n",
    "    (\"extractor\", WordExtractor(stop_words)),\n",
    "    (\"stemmer\", ApplyStemmer(PorterStemmer())),\n",
    "    (\"vectorizer\", CountVectorizer()),\n",
    "    (\"logic\",LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "94360028",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df['text'].values\n",
    "y=df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6766f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "06cb41a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('norm', TextNormalizer()),\n",
       "                ('extractor',\n",
       "                 WordExtractor(stop_words=['i', 'me', 'my', 'myself', 'we',\n",
       "                                           'our', 'ours', 'ourselves', 'you',\n",
       "                                           \"you're\", \"you've\", \"you'll\",\n",
       "                                           \"you'd\", 'your', 'yours', 'yourself',\n",
       "                                           'yourselves', 'he', 'him', 'his',\n",
       "                                           'himself', 'she', \"she's\", 'her',\n",
       "                                           'hers', 'herself', 'it', \"it's\",\n",
       "                                           'its', 'itself', ...])),\n",
       "                ('stemmer', ApplyStemmer(stemmer=<PorterStemmer>)),\n",
       "                ('vectorizer', CountVectorizer()),\n",
       "                ('logic', LogisticRegression())])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "566275f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred= pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e18c474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7291256400157542"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2513dce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fcb73960",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(pipe, open(\"nlp_pipe.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "814807d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
